
# ğŸ¥ AI-Based Video Content Moderation System

This project implements an AI-powered video content moderation pipeline using deep learning techniques. It automatically analyzes videos, extracts features from each frame using a pretrained **ResNet-50 CNN**, and uses an **LSTM** (Long Short-Term Memory) model to learn temporal patterns across frames to classify the video as **Safe** or **Inappropriate**.

---

## ğŸ“Œ Features

- ğŸ” Frame-wise feature extraction using **ResNet-50**
- ğŸ§  Temporal sequence modeling using **LSTM**
- âœ… Binary classification: Safe (`0`) vs Inappropriate (`1`)
- ğŸ§ª Modular, extensible design for adding your own training datasets
- ğŸ“ˆ Reduces manual review effort and improves policy compliance

---

## ğŸ—‚ï¸ Project Structure

```
video_moderation/
â”‚
â”œâ”€â”€ data/                      # Input videos (.mp4)
â”œâ”€â”€ frames/                    # Extracted frames from video
â”‚
â”œâ”€â”€ model/
â”‚   â”œâ”€â”€ cnn_extractor.py       # ResNet50-based feature extractor
â”‚   â””â”€â”€ lstm_classifier.py     # LSTM for temporal classification
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ video_utils.py         # Frame extraction helper
â”‚   â””â”€â”€ visualize.py           # Optional: plot confidence scores
â”‚
â”œâ”€â”€ main.py                    # Inference pipeline (no training yet)
â”œâ”€â”€ requirements.txt           # Python package dependencies
â””â”€â”€ README.md                  # Project documentation
```

---

## ğŸ“½ï¸ How It Works

### â¤ Data Flow Diagram

```
   Input Video
       â”‚
[Frame Extraction: 1 fps]
       â”‚
[ResNet-50 CNN]  â†’ 2048-D feature per frame
       â”‚
[Sequence of Frame Features]
       â”‚
[LSTM Model] â†’ Learns temporal behavior
       â”‚
[Classifier] â†’ Safe or Inappropriate
```

---

## ğŸ”§ Requirements

Install dependencies using:

```bash
pip install -r requirements.txt
```

Required Python packages:
- `torch`, `torchvision`
- `opencv-python`
- `numpy`
- `matplotlib`
- `tqdm`

---

## ğŸš€ How to Run

1. Place a sample video inside the `data/` folder:
   ```bash
   data/sample_sports_video.mp4
   ```

2. Run the main pipeline:
   ```bash
   python main.py
   ```

3. Output:
   - Extracts 1 frame/sec
   - Prints model prediction: **Safe âœ…** or **Inappropriate âŒ**

---

## ğŸ§  Whatâ€™s Special About ResNet-50?

- Converts each video frame into a **2048-dimensional feature vector**
- Captures semantic features like objects, people, scenes
- Acts as a **feature extractor** for the LSTM
- Can be replaced with other CNNs (EfficientNet, DINO, etc.)

---

## ğŸ“¦ Next Steps (Future Work)

- [ ] Integrate live webcam or video streaming input
- [ ] Support multi-class moderation categories
- [ ] Build a web API using FastAPI or Flask

---

## ğŸ“š Related Concepts

- CNN (ResNet): For spatial understanding of individual frames
- LSTM: For learning temporal patterns across video frames
- Feature extraction vs classification
- Transfer learning and sequence modeling
- Safe content detection in sports / general video moderation

---

## ğŸ¤– Authors

- Developed by SRI VIDHYA
- Designed for ML video moderation research and prototyping

---

## ğŸ“„ License

MIT License â€” feel free to use and modify for educational or commercial use.

---
